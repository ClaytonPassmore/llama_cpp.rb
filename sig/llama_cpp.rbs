module LLaMACpp
  VERSION: String
  LLAMA_CPP_VERSION: String
  LLAMA_FILE_VERSION: String
  LLAMA_FILE_MAGIC: String
  LLAMA_FILE_MAGIC_UNVERSIONED: String

  LLAMA_FTYPE_ALL_F32: Integer
  LLAMA_FTYPE_MOSTLY_F16: Integer
  LLAMA_FTYPE_MOSTLY_Q4_0: Integer
  LLAMA_FTYPE_MOSTLY_Q4_1: Integer
  LLAMA_FTYPE_MOSTLY_Q4_1_SOME_F16: Integer
  LLAMA_FTYPE_MOSTLY_Q4_2: Integer
  LLAMA_FTYPE_MOSTLY_Q8_0: Integer
  LLAMA_FTYPE_MOSTLY_Q5_0: Integer
  LLAMA_FTYPE_MOSTLY_Q5_1: Integer

  def self?.model_quantize: (input_path: String, output_path: String, ftype: Integer, ?n_threads: Integer) -> void
  def self?.generate: (::LLaMACpp::Context, String, ?n_predict: Integer, ?n_threads: Integer) -> String
  def self?.print_system_info: () -> void
  def self?.token_bos: () -> Integer
  def self?.token_eos: () -> Integer
  def self?.token_nl: () -> Integer
  def self?.mmap_supported?: () -> bool
  def self?.mlock_supported?: () -> bool

  class TokenData
    public

    def id: () -> Integer
    def id=: (Integer) -> Integer
    def logit: () -> Float
    def logit=: (Float) -> Float
    def p: () -> Float
    def p=: (Float) -> Float
  end

  class TokenDataArray
    public

    def initialize: (Array[::LLaMACpp::TokenData], ?sorted: bool) -> void
    def size: () -> Integer
    def sorted: () -> bool
  end

  class Context
    public

    def initialize: (model_path: String, params: ::LLaMACpp::ContextParams) -> void
                  | () -> void
    def embeddings: () -> Array[Float]
    def empty?: () -> bool
    def eval: (tokens: Array[Integer], n_past: Integer, ?n_tokens: Integer, ?n_threads: Integer) -> void
    def free: () -> void
    def load: (model_path: String, params: ::LLaMACpp::ContextParams) -> void
    def logits: () -> Array[Float]
    def n_ctx: () -> Integer
    def n_embd: () -> Integer
    def n_vocab: () -> Integer
    def print_timings: () -> void
    def reset_timings: () -> void
    def token_to_str: (Integer) -> String
    def tokenize: (text: String, ?n_max_tokens: Integer, ?add_bos: bool) -> Array[Integer]
    def apply_lora_from_file: (lora_path: String, ?base_model_path: String, ?n_threads: Integer) -> void
    def kv_cache_token_count: () -> Integer
    def set_rng_seed: (Integer) -> void
    def sample_token_mirostat_v2: (::LLaMACpp::TokenDataArray, tau: Float, eta: Float, mu: Float) -> [Integer, Float]
    def sample_token_greedy: (::LLaMACpp::TokenDataArray) -> Integer
    def sample_token: (::LLaMACpp::TokenDataArray) -> Integer
  end

  class ContextParams
    public

    def embedding: () -> bool
    def embedding=: (bool) -> bool
    def f16_kv: () -> bool
    def f16_kv=: (bool) -> bool
    def logits_all: () -> bool
    def logits_all=: (bool) -> bool
    def n_ctx: () -> Integer
    def n_ctx=: (Integer) -> Integer
    def n_parts: () -> Integer
    def n_parts=: (Integer) -> Integer
    def seed: () -> Integer
    def seed=: (Integer) -> Integer
    def use_mlock: () -> bool
    def use_mlock=: (bool) -> bool
    def use_mmap: () -> bool
    def use_mmap=: (bool) -> bool
    def vocab_only: () -> bool
    def vocab_only=: (bool) -> bool
  end

  class Params = ContextParams

  class Client
    def initialize(model_path: String, ?lora_adapter_path: String, ?lora_base_path: String,
                   ?n_ctx: Integer, ?n_parts: Integer, ?memory_f16: bool, ?use_mmap: bool, ?use_mlock: bool,
                   ?embedding: bool, ?n_threads: Integer, ?seed: Integer) -> void
    def completions(String, ?max_tokens: Integer, ?n_keep: Integer, ?repeat_last_n: Integer, ?n_batch: Integer,
                    ?top_k: Integer, ?top_p: Float, ?temperature: Float, ?repeat_penalty: Float) -> String
    def embeddings(String) -> Array[Float]
  end
end
